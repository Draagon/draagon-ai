"""Phase 0 Integration and Edge Case Tests.

These tests verify:
1. Full pipeline integration: Content Analysis ‚Üí WSD ‚Üí Entity Classification
2. Edge cases: Unicode, long inputs, malformed LLM responses
3. Phase 0 readiness for downstream phases (decomposition)

Created as part of Phase 0 code review recommendations.
"""

import pytest
import sys
from pathlib import Path
from unittest.mock import AsyncMock, MagicMock

# Add prototype src to path
prototype_root = Path(__file__).parent.parent
src_path = prototype_root / "src"
if str(src_path) not in sys.path:
    sys.path.insert(0, str(src_path))

from content_analyzer import ContentAnalyzer, ContentType
from content_aware_wsd import ContentAwareWSD, ContentAwareWSDResult
from entity_classifier import EntityClassifier, ClassifierConfig
from identifiers import EntityType, UniversalSemanticIdentifier, create_instance_identifier
from wsd import WSDConfig, WordSenseDisambiguator


# =============================================================================
# Fixtures
# =============================================================================


@pytest.fixture
def content_analyzer():
    """Content analyzer without LLM."""
    return ContentAnalyzer()


@pytest.fixture
def content_aware_wsd():
    """Content-aware WSD processor."""
    return ContentAwareWSD(require_wordnet=False)


@pytest.fixture
def entity_classifier():
    """Entity classifier without LLM."""
    config = ClassifierConfig()
    return EntityClassifier(config, llm=None)


@pytest.fixture
def mock_llm():
    """Mock LLM provider for testing malformed response handling."""
    mock = AsyncMock()
    return mock


# =============================================================================
# Full Pipeline Integration Tests
# =============================================================================


class TestFullPipelineIntegration:
    """Test the complete Phase 0 pipeline: Content ‚Üí WSD ‚Üí Entity."""

    @pytest.mark.asyncio
    async def test_prose_pipeline_doug_forgot_keys(
        self, content_analyzer, content_aware_wsd, entity_classifier
    ):
        """Full pipeline for: 'Doug forgot his keys again.'

        This sentence tests:
        - PROSE content type detection
        - WSD on 'forgot' (verb), 'keys' (noun)
        - Entity classification: Doug (INSTANCE), keys (CLASS)
        - Presupposition trigger: 'again' (iterative)
        """
        text = "Doug forgot his keys again."

        # Step 1: Content analysis
        content_analysis = await content_analyzer.analyze(text)
        assert content_analysis.content_type == ContentType.PROSE
        assert content_analysis.has_natural_language()

        # Step 2: Content-aware WSD
        wsd_result = await content_aware_wsd.process(text)
        assert wsd_result.content_analysis is not None
        assert wsd_result.content_analysis.content_type == ContentType.PROSE
        # WSD results depend on WordNet availability

        # Step 3: Entity classification for key entities
        doug_entity = entity_classifier.classify_sync("Doug", text)
        keys_entity = entity_classifier.classify_sync("keys", text)

        # Doug should be INSTANCE (proper noun, person name)
        assert doug_entity.entity_type == EntityType.INSTANCE

        # keys should be CLASS (common noun)
        assert keys_entity.entity_type == EntityType.CLASS

    @pytest.mark.asyncio
    async def test_prose_pipeline_bank_ambiguity(
        self, content_analyzer, content_aware_wsd, entity_classifier
    ):
        """Full pipeline for ambiguous 'bank' sentence.

        Tests WSD-first principle: bank must be disambiguated before storage.
        """
        text = "She deposited money at the bank near the river bank."

        # Step 1: Content analysis
        content_analysis = await content_analyzer.analyze(text)
        assert content_analysis.content_type == ContentType.PROSE

        # Step 2: Content-aware WSD
        wsd_result = await content_aware_wsd.process(text)
        assert wsd_result.content_analysis is not None

        # Step 3: Entity classification
        # 'She' should be ANAPHORA (pronoun needing resolution)
        she_entity = entity_classifier.classify_sync("She", text)
        assert she_entity.entity_type == EntityType.ANAPHORA

        # 'money' should be CLASS
        money_entity = entity_classifier.classify_sync("money", text)
        assert money_entity.entity_type == EntityType.CLASS

    @pytest.mark.asyncio
    async def test_code_pipeline_skips_wsd_on_syntax(
        self, content_analyzer, content_aware_wsd
    ):
        """Code content detection depends on heuristics.

        Note: Short code snippets may be classified as PROSE by heuristics
        because they lack enough code indicators. This is a known limitation
        of heuristic fallback. With LLM analysis, code would be detected.
        """
        code = '''
def process_bank_transaction(account, amount):
    """Process a bank transaction."""
    return account.deposit(amount)
'''
        # Step 1: Content analysis
        content_analysis = await content_analyzer.analyze(code)
        # Heuristics may detect as PROSE for short snippets
        # All types are valid - key is no crash
        assert content_analysis.content_type in [
            ContentType.CODE, ContentType.MIXED, ContentType.PROSE
        ]

        # Step 2: Content-aware WSD
        wsd_result = await content_aware_wsd.process(code)

        # For code, WSD should only process NL portions (docstrings)
        # Not the variable names or keywords
        assert wsd_result.content_analysis is not None

    @pytest.mark.asyncio
    async def test_mixed_content_pipeline(
        self, content_analyzer, content_aware_wsd
    ):
        """Mixed content (markdown with code) handles both appropriately."""
        mixed_content = """# Bank Account Module

This module handles bank account operations including deposits and withdrawals.

```python
class BankAccount:
    def deposit(self, amount):
        self.balance += amount
```

The bank stores customer data securely.
"""
        # Step 1: Content analysis
        content_analysis = await content_analyzer.analyze(mixed_content)
        assert content_analysis.has_natural_language()

        # Step 2: Content-aware WSD processes NL portions
        wsd_result = await content_aware_wsd.process(mixed_content)
        assert wsd_result.content_analysis is not None


# =============================================================================
# Edge Case Tests
# =============================================================================


class TestUnicodeHandling:
    """Test handling of Unicode content."""

    @pytest.mark.asyncio
    async def test_unicode_emoji_content(self, content_analyzer):
        """Content with emojis should not crash."""
        text = "Doug is happy üòÄ about the meeting üìÖ tomorrow!"
        analysis = await content_analyzer.analyze(text)
        assert analysis.content_type == ContentType.PROSE
        assert analysis.has_natural_language()

    @pytest.mark.asyncio
    async def test_unicode_multilingual_mixed(self, content_analyzer):
        """Mixed language content should be handled."""
        text = "Doug said „Åì„Çì„Å´„Å°„ÅØ (hello) at the meeting."
        analysis = await content_analyzer.analyze(text)
        # Should not crash, type detection may vary
        assert analysis.content_type is not None

    @pytest.mark.asyncio
    async def test_unicode_chinese_text(self, content_analyzer):
        """Chinese text should be analyzed without crash."""
        text = "Doug Âéª‰∫ÜÈì∂Ë°åÂ≠òÈí±„ÄÇ"  # Doug went to the bank to deposit money
        analysis = await content_analyzer.analyze(text)
        assert analysis.content_type is not None

    @pytest.mark.asyncio
    async def test_unicode_arabic_rtl(self, content_analyzer):
        """Arabic RTL text should be handled."""
        text = "ÿ∞Ÿáÿ® ÿØŸàÿ¨ ÿ•ŸÑŸâ ÿßŸÑÿ®ŸÜŸÉ"  # Doug went to the bank
        analysis = await content_analyzer.analyze(text)
        assert analysis.content_type is not None

    @pytest.mark.asyncio
    async def test_unicode_special_characters(self, content_analyzer):
        """Special characters and symbols should not crash."""
        text = "The price is ‚Ç¨50 or ¬£40 or ¬•5000 for the ¬© item‚Ñ¢"
        analysis = await content_analyzer.analyze(text)
        assert analysis.content_type == ContentType.PROSE

    @pytest.mark.asyncio
    async def test_wsd_with_unicode(self, content_aware_wsd):
        """WSD should handle Unicode gracefully."""
        text = "Doug said „Åì„Çì„Å´„Å°„ÅØ at the bank üè¶"
        # Should not crash
        result = await content_aware_wsd.process(text)
        assert result.content_analysis is not None


class TestLongInputHandling:
    """Test handling of very long inputs."""

    @pytest.mark.asyncio
    async def test_long_prose_content(self, content_analyzer):
        """Very long prose should be handled (10K+ chars)."""
        # Generate long prose by repeating sentences
        base_sentence = "Doug went to the bank to deposit money. "
        long_text = base_sentence * 400  # ~15K characters

        analysis = await content_analyzer.analyze(long_text)
        assert analysis.content_type == ContentType.PROSE
        assert analysis.has_natural_language()

    @pytest.mark.asyncio
    async def test_long_code_content(self, content_analyzer):
        """Very long code should be handled."""
        base_function = '''
def process_item_{n}(item):
    """Process item number {n}."""
    return item * {n}

'''
        long_code = "\n".join(
            base_function.format(n=i) for i in range(200)
        )  # ~10K characters

        analysis = await content_analyzer.analyze(long_code)
        # Should detect as CODE
        assert analysis.content_type in [ContentType.CODE, ContentType.PROSE]

    @pytest.mark.asyncio
    async def test_content_aware_wsd_long_input(self, content_aware_wsd):
        """Content-aware WSD should handle long inputs."""
        base_sentence = "The bank is near the river. "
        long_text = base_sentence * 200  # ~6K characters

        # Should not crash or timeout
        result = await content_aware_wsd.process(long_text)
        assert result.content_analysis is not None


class TestMalformedLLMResponses:
    """Test handling of malformed LLM responses."""

    @pytest.mark.asyncio
    async def test_empty_llm_response(self, mock_llm):
        """Empty LLM response should be handled gracefully."""
        mock_llm.chat.return_value = ""

        analyzer = ContentAnalyzer(llm=mock_llm)
        # Should fall back to heuristics
        analysis = await analyzer.analyze("Doug went to the bank.")
        assert analysis.content_type is not None

    @pytest.mark.asyncio
    async def test_invalid_xml_response(self, mock_llm):
        """Invalid XML should be handled gracefully."""
        mock_llm.chat.return_value = "<content_type>PROSE</content_type>NOT CLOSED"

        analyzer = ContentAnalyzer(llm=mock_llm)
        # Should fall back to heuristics
        analysis = await analyzer.analyze("Doug went to the bank.")
        assert analysis.content_type is not None

    @pytest.mark.asyncio
    async def test_unexpected_content_type_response(self, mock_llm):
        """Unknown content type should fall back gracefully."""
        mock_llm.chat.return_value = """
<analysis>
    <content_type>UNKNOWN_TYPE</content_type>
    <confidence>0.9</confidence>
</analysis>
"""
        analyzer = ContentAnalyzer(llm=mock_llm)
        # Should handle unknown type
        analysis = await analyzer.analyze("Doug went to the bank.")
        assert analysis.content_type is not None

    @pytest.mark.asyncio
    async def test_llm_exception_recovery(self, mock_llm):
        """LLM exception should fall back to heuristics."""
        mock_llm.chat.side_effect = Exception("API Error")

        analyzer = ContentAnalyzer(llm=mock_llm)
        # Should fall back to heuristics without crashing
        analysis = await analyzer.analyze("Doug went to the bank.")
        assert analysis.content_type is not None

    @pytest.mark.asyncio
    async def test_llm_timeout_simulation(self, mock_llm):
        """Simulated timeout should be handled."""
        import asyncio

        async def slow_response(*args, **kwargs):
            await asyncio.sleep(0.1)
            raise asyncio.TimeoutError("Simulated timeout")

        mock_llm.chat.side_effect = slow_response

        analyzer = ContentAnalyzer(llm=mock_llm)
        # Should fall back to heuristics
        analysis = await analyzer.analyze("Doug went to the bank.")
        assert analysis.content_type is not None


class TestEntityClassifierEdgeCases:
    """Test entity classifier edge cases."""

    def test_empty_string(self, entity_classifier):
        """Empty string should be handled."""
        result = entity_classifier.classify_sync("", "Some context")
        # Should not crash, result may be None or GENERIC
        assert result is None or result.entity_type is not None

    def test_whitespace_only(self, entity_classifier):
        """Whitespace-only text should be handled."""
        result = entity_classifier.classify_sync("   ", "Some context")
        assert result is None or result.entity_type is not None

    def test_single_character(self, entity_classifier):
        """Single character should be handled.

        Note: 'I' at sentence start is ambiguous - could be pronoun (anaphora)
        or capitalized proper noun (instance). Heuristics see capitalization
        and may classify as INSTANCE. This is a known edge case.
        """
        result = entity_classifier.classify_sync("I", "I went to the store")
        # 'I' is ambiguous - could be anaphora (pronoun) or instance (capital)
        if result:
            assert result.entity_type in [
                EntityType.ANAPHORA, EntityType.GENERIC, EntityType.INSTANCE
            ]

    def test_numbers_only(self, entity_classifier):
        """Numbers should be classified."""
        result = entity_classifier.classify_sync("42", "The answer is 42")
        # Numbers could be INSTANCE (specific value) or CLASS (the concept of 42)
        assert result is None or result.entity_type is not None

    def test_special_punctuation(self, entity_classifier):
        """Punctuation should be handled."""
        result = entity_classifier.classify_sync("...", "And then...")
        assert result is None or result.entity_type is not None


class TestPhase0ReadinessForDecomposition:
    """Test that Phase 0 outputs are ready for Phase 1 decomposition."""

    @pytest.mark.asyncio
    async def test_identifier_serialization_roundtrip(self):
        """Identifiers should serialize and deserialize correctly."""
        original = create_instance_identifier(
            name="Doug",
            wikidata_qid=None,
            aliases=["Douglas"],
            confidence=0.95,
        )

        # Serialize to dict
        as_dict = original.to_dict()
        assert as_dict["canonical_name"] == "Doug"
        assert as_dict["entity_type"] == "instance"

        # Deserialize back
        restored = UniversalSemanticIdentifier.from_dict(as_dict)
        assert restored.canonical_name == "Doug"
        assert restored.entity_type == EntityType.INSTANCE
        assert restored.confidence == 0.95

        # Serialize to JSON
        as_json = original.to_json()
        restored_from_json = UniversalSemanticIdentifier.from_json(as_json)
        assert restored_from_json.canonical_name == "Doug"

    @pytest.mark.asyncio
    async def test_content_analysis_provides_nl_text(self, content_analyzer):
        """Content analysis should provide NL text for decomposition."""
        mixed_content = """# Documentation

This is prose that should be extracted.

```python
# This is code
def foo(): pass
```

More prose here.
"""
        analysis = await content_analyzer.analyze(mixed_content)

        # Should have NL text for decomposition
        assert analysis.has_natural_language()
        nl_text = analysis.get_natural_language_text()
        assert nl_text is not None
        assert len(nl_text) > 0

    @pytest.mark.asyncio
    async def test_wsd_result_contains_disambiguations(self, content_aware_wsd):
        """WSD result should contain disambiguation data for decomposition."""
        text = "Doug went to the bank."
        result = await content_aware_wsd.process(text)

        # Result should have content analysis
        assert result.content_analysis is not None

        # Result structure should be ready for decomposition
        # (Actual disambiguations depend on WordNet availability)
        assert isinstance(result, ContentAwareWSDResult)

    def test_entity_classifier_provides_confidence(self, entity_classifier):
        """Entity classification should include confidence for weighting."""
        result = entity_classifier.classify_sync("Doug", "Doug went to the store")

        assert result is not None
        assert result.entity_type == EntityType.INSTANCE
        assert hasattr(result, "confidence")
        assert 0.0 <= result.confidence <= 1.0
