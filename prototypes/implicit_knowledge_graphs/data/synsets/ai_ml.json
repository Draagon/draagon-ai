{
  "domain": "AI_ML",
  "synsets": [
    {
      "synset_id": "llm.ai.01",
      "word": "llm",
      "pos": "n",
      "definition": "a large language model, a deep learning model trained on vast text data to understand and generate human-like text",
      "examples": ["GPT-4 is an advanced LLM", "The LLM generates coherent responses to prompts"],
      "hypernyms": ["language_model.ai.01", "neural_network.ai.01"],
      "hyponyms": ["gpt.ai.01", "claude.ai.01", "llama.ai.01"],
      "aliases": ["large_language_model"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "transformer.ai.01",
      "word": "transformer",
      "pos": "n",
      "definition": "a neural network architecture using self-attention mechanisms, foundational to modern language models",
      "examples": ["Transformers revolutionized NLP", "The transformer architecture enables parallel processing of sequences"],
      "hypernyms": ["neural_network_architecture.ai.01"],
      "hyponyms": [],
      "aliases": ["transformer_model"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "attention.ai.01",
      "word": "attention",
      "pos": "n",
      "definition": "a mechanism in neural networks that allows models to focus on relevant parts of input when producing output",
      "examples": ["Self-attention enables transformers to capture long-range dependencies", "Multi-head attention processes information in parallel"],
      "hypernyms": ["neural_network_mechanism.ai.01"],
      "hyponyms": ["self_attention.ai.01", "cross_attention.ai.01"],
      "aliases": ["attention_mechanism"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "embedding.ai.01",
      "word": "embedding",
      "pos": "n",
      "definition": "a dense vector representation of discrete data (words, tokens, entities) in continuous vector space",
      "examples": ["Word embeddings capture semantic relationships", "Generate embeddings for semantic search"],
      "hypernyms": ["vector_representation.ai.01"],
      "hyponyms": ["word_embedding.ai.01", "sentence_embedding.ai.01"],
      "aliases": ["vector_embedding", "dense_embedding"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "token.ai.01",
      "word": "token",
      "pos": "n",
      "definition": "the smallest unit of text processed by a language model, which may be a word, subword, or character",
      "examples": ["GPT uses byte-pair encoding for tokenization", "The model has a context window of 128K tokens"],
      "hypernyms": ["text_unit.ai.01"],
      "hyponyms": [],
      "aliases": [],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "context_window.ai.01",
      "word": "context_window",
      "pos": "n",
      "definition": "the maximum number of tokens an LLM can process in a single inference, defining how much text it can consider",
      "examples": ["Claude has a 200K token context window", "Longer context windows enable processing entire documents"],
      "hypernyms": ["model_parameter.ai.01"],
      "hyponyms": [],
      "aliases": ["context_length", "max_tokens"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "fine_tuning.ai.01",
      "word": "fine_tuning",
      "pos": "n",
      "definition": "the process of further training a pre-trained model on domain-specific data to improve performance on specific tasks",
      "examples": ["Fine-tune the model on medical texts", "Fine-tuning adapts the model to your use case"],
      "hypernyms": ["training_technique.ai.01"],
      "hyponyms": ["lora.ai.01", "qlora.ai.01", "sft.ai.01"],
      "aliases": ["finetuning"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "lora.ai.01",
      "word": "lora",
      "pos": "n",
      "definition": "Low-Rank Adaptation, a parameter-efficient fine-tuning technique that trains small rank decomposition matrices instead of full model weights",
      "examples": ["LoRA reduces fine-tuning memory requirements", "Apply LoRA adapters to customize the model"],
      "hypernyms": ["fine_tuning.ai.01", "peft.ai.01"],
      "hyponyms": [],
      "aliases": ["low_rank_adaptation"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "qlora.ai.01",
      "word": "qlora",
      "pos": "n",
      "definition": "Quantized LoRA, a technique combining 4-bit quantization with LoRA to enable fine-tuning large models on consumer hardware",
      "examples": ["QLoRA enables fine-tuning 65B models on a single GPU", "Use QLoRA for efficient adaptation"],
      "hypernyms": ["lora.ai.01"],
      "hyponyms": [],
      "aliases": ["quantized_lora"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "rlhf.ai.01",
      "word": "rlhf",
      "pos": "n",
      "definition": "Reinforcement Learning from Human Feedback, a technique to align language models with human preferences using reward models",
      "examples": ["RLHF improves model helpfulness and safety", "ChatGPT was trained using RLHF"],
      "hypernyms": ["training_technique.ai.01", "reinforcement_learning.ai.01"],
      "hyponyms": [],
      "aliases": ["reinforcement_learning_from_human_feedback"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "sft.ai.01",
      "word": "sft",
      "pos": "n",
      "definition": "Supervised Fine-Tuning, training a model on examples of desired input-output pairs to improve task performance",
      "examples": ["SFT on instruction data improves following instructions", "Use SFT before RLHF"],
      "hypernyms": ["fine_tuning.ai.01"],
      "hyponyms": [],
      "aliases": ["supervised_fine_tuning"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "rag.ai.01",
      "word": "rag",
      "pos": "n",
      "definition": "Retrieval-Augmented Generation, a technique that enhances LLM responses by retrieving relevant information from external knowledge bases",
      "examples": ["RAG reduces hallucinations by grounding responses in documents", "Implement RAG with a vector database"],
      "hypernyms": ["ai_technique.ai.01"],
      "hyponyms": [],
      "aliases": ["retrieval_augmented_generation"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "chunking.ai.01",
      "word": "chunking",
      "pos": "n",
      "definition": "the process of splitting documents into smaller pieces for embedding and retrieval in RAG systems",
      "examples": ["Use semantic chunking for better retrieval", "Chunk size affects retrieval quality"],
      "hypernyms": ["preprocessing.ai.01"],
      "hyponyms": [],
      "aliases": ["text_chunking", "document_chunking"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "reranking.ai.01",
      "word": "reranking",
      "pos": "n",
      "definition": "a retrieval technique that uses a more sophisticated model to reorder initial search results for improved relevance",
      "examples": ["Apply reranking to improve retrieval precision", "Cross-encoder reranking produces better results"],
      "hypernyms": ["retrieval_technique.ai.01"],
      "hyponyms": [],
      "aliases": ["re_ranking", "reranker"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "perplexity.ai.01",
      "word": "perplexity",
      "pos": "n",
      "definition": "a metric measuring how well a language model predicts text, with lower values indicating better performance",
      "examples": ["The model achieved low perplexity on the test set", "Perplexity measures model uncertainty"],
      "hypernyms": ["evaluation_metric.ai.01"],
      "hyponyms": [],
      "aliases": ["ppl"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "bleu.ai.01",
      "word": "bleu",
      "pos": "n",
      "definition": "Bilingual Evaluation Understudy, a metric for evaluating machine translation quality by comparing n-gram overlap with references",
      "examples": ["The translation achieved a BLEU score of 35", "BLEU correlates with human judgment of translation quality"],
      "hypernyms": ["evaluation_metric.ai.01"],
      "hyponyms": [],
      "aliases": ["bleu_score"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "rouge.ai.01",
      "word": "rouge",
      "pos": "n",
      "definition": "Recall-Oriented Understudy for Gisting Evaluation, metrics for evaluating text summarization by measuring overlap with reference summaries",
      "examples": ["ROUGE-L measures longest common subsequence", "Evaluate summaries using ROUGE scores"],
      "hypernyms": ["evaluation_metric.ai.01"],
      "hyponyms": [],
      "aliases": ["rouge_score"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "gpt.ai.01",
      "word": "gpt",
      "pos": "n",
      "definition": "Generative Pre-trained Transformer, a family of large language models by OpenAI trained on internet text",
      "examples": ["GPT-4 is OpenAI's most capable model", "GPT models use decoder-only transformer architecture"],
      "hypernyms": ["llm.ai.01"],
      "hyponyms": ["gpt4.ai.01", "gpt3.ai.01"],
      "aliases": ["generative_pretrained_transformer"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "claude.ai.01",
      "word": "claude",
      "pos": "n",
      "definition": "a family of large language models by Anthropic, designed to be helpful, harmless, and honest",
      "examples": ["Claude Opus 4.5 is Anthropic's most capable model", "Claude is trained using Constitutional AI"],
      "hypernyms": ["llm.ai.01"],
      "hyponyms": [],
      "aliases": ["claude_ai"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "llama.ai.01",
      "word": "llama",
      "pos": "n",
      "definition": "Large Language Model Meta AI, a family of open-weight language models released by Meta",
      "examples": ["Llama 3 is available for commercial use", "Fine-tune Llama for your specific use case"],
      "hypernyms": ["llm.ai.01"],
      "hyponyms": [],
      "aliases": ["meta_llama"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "mistral.ai.01",
      "word": "mistral",
      "pos": "n",
      "definition": "a family of efficient open-weight language models by Mistral AI, known for strong performance relative to size",
      "examples": ["Mistral 7B outperforms larger models", "Use Mistral for cost-effective inference"],
      "hypernyms": ["llm.ai.01"],
      "hyponyms": [],
      "aliases": ["mistral_ai"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "gemini.ai.01",
      "word": "gemini",
      "pos": "n",
      "definition": "a family of multimodal AI models by Google DeepMind, capable of processing text, images, audio, and video",
      "examples": ["Gemini Pro handles text and images", "Gemini is Google's flagship AI model"],
      "hypernyms": ["llm.ai.01", "multimodal_model.ai.01"],
      "hyponyms": [],
      "aliases": ["google_gemini"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "prompt_engineering.ai.01",
      "word": "prompt_engineering",
      "pos": "n",
      "definition": "the practice of designing effective prompts to guide language models toward desired outputs",
      "examples": ["Good prompt engineering improves model responses", "Use few-shot examples in your prompts"],
      "hypernyms": ["ai_technique.ai.01"],
      "hyponyms": [],
      "aliases": ["prompting"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "few_shot.ai.01",
      "word": "few_shot",
      "pos": "n",
      "definition": "a prompting technique that provides a small number of examples to guide model behavior without fine-tuning",
      "examples": ["Few-shot prompting improves task performance", "Include 2-3 examples for few-shot learning"],
      "hypernyms": ["prompt_engineering.ai.01"],
      "hyponyms": [],
      "aliases": ["few_shot_learning", "few_shot_prompting"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "zero_shot.ai.01",
      "word": "zero_shot",
      "pos": "n",
      "definition": "a prompting technique where models perform tasks without any task-specific examples, relying only on instructions",
      "examples": ["Zero-shot classification requires no training examples", "Test zero-shot capabilities first"],
      "hypernyms": ["prompt_engineering.ai.01"],
      "hyponyms": [],
      "aliases": ["zero_shot_learning", "zero_shot_prompting"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "chain_of_thought.ai.01",
      "word": "chain_of_thought",
      "pos": "n",
      "definition": "a prompting technique that encourages models to break down complex reasoning into intermediate steps",
      "examples": ["Chain of thought improves math problem solving", "Add 'Let's think step by step' to enable CoT"],
      "hypernyms": ["prompt_engineering.ai.01"],
      "hyponyms": [],
      "aliases": ["cot", "cot_prompting"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "hallucination.ai.01",
      "word": "hallucination",
      "pos": "n",
      "definition": "when a language model generates plausible-sounding but factually incorrect or fabricated information",
      "examples": ["RAG helps reduce hallucinations", "Always verify model outputs for hallucinations"],
      "hypernyms": ["model_behavior.ai.01"],
      "hyponyms": [],
      "aliases": ["ai_hallucination"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "inference.ai.01",
      "word": "inference",
      "pos": "n",
      "definition": "the process of using a trained model to make predictions or generate outputs on new inputs",
      "examples": ["Run inference on the production model", "Inference latency affects user experience"],
      "hypernyms": ["model_operation.ai.01"],
      "hyponyms": [],
      "aliases": ["model_inference"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "quantization.ai.01",
      "word": "quantization",
      "pos": "n",
      "definition": "reducing model precision (e.g., from 32-bit to 4-bit) to decrease memory usage and increase inference speed",
      "examples": ["4-bit quantization enables running 70B models locally", "Quantization trades accuracy for efficiency"],
      "hypernyms": ["optimization_technique.ai.01"],
      "hyponyms": [],
      "aliases": ["model_quantization"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "temperature.ai.01",
      "word": "temperature",
      "pos": "n",
      "definition": "a parameter controlling randomness in model outputs, with higher values producing more diverse responses",
      "examples": ["Use temperature 0 for deterministic outputs", "Higher temperature increases creativity"],
      "hypernyms": ["model_parameter.ai.01"],
      "hyponyms": [],
      "aliases": [],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "top_p.ai.01",
      "word": "top_p",
      "pos": "n",
      "definition": "nucleus sampling parameter that limits token selection to the smallest set whose cumulative probability exceeds p",
      "examples": ["Set top_p to 0.9 for balanced generation", "Top-p sampling produces more coherent text than temperature alone"],
      "hypernyms": ["model_parameter.ai.01"],
      "hyponyms": [],
      "aliases": ["nucleus_sampling", "topp"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "agent.ai.01",
      "word": "agent",
      "pos": "n",
      "definition": "an AI system that can perceive its environment, make decisions, and take actions to achieve goals autonomously",
      "examples": ["Build an agent that can browse the web", "The agent uses tools to complete tasks"],
      "hypernyms": ["ai_system.ai.01"],
      "hyponyms": [],
      "aliases": ["ai_agent", "autonomous_agent"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "tool_use.ai.01",
      "word": "tool_use",
      "pos": "n",
      "definition": "the capability of language models to invoke external functions or APIs to extend their capabilities",
      "examples": ["Enable tool use for the agent to search the web", "Tool use allows models to perform calculations"],
      "hypernyms": ["model_capability.ai.01"],
      "hyponyms": [],
      "aliases": ["function_calling"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "multimodal.ai.01",
      "word": "multimodal",
      "pos": "n",
      "definition": "AI models that can process and generate multiple types of data including text, images, audio, and video",
      "examples": ["Multimodal models understand images and text together", "GPT-4V is a multimodal model"],
      "hypernyms": ["model_type.ai.01"],
      "hyponyms": [],
      "aliases": ["multimodal_ai", "multimodal_model"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "vision_language_model.ai.01",
      "word": "vision_language_model",
      "pos": "n",
      "definition": "a multimodal model that can understand and reason about both images and text",
      "examples": ["Use a VLM to analyze screenshots", "Vision-language models can describe images"],
      "hypernyms": ["multimodal.ai.01"],
      "hyponyms": [],
      "aliases": ["vlm"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "diffusion_model.ai.01",
      "word": "diffusion_model",
      "pos": "n",
      "definition": "a generative model that creates data by learning to reverse a gradual noising process",
      "examples": ["Stable Diffusion is a popular diffusion model", "Diffusion models excel at image generation"],
      "hypernyms": ["generative_model.ai.01"],
      "hyponyms": ["stable_diffusion.ai.01"],
      "aliases": [],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "stable_diffusion.ai.01",
      "word": "stable_diffusion",
      "pos": "n",
      "definition": "an open-source text-to-image diffusion model that generates images from text descriptions",
      "examples": ["Generate images with Stable Diffusion", "Stable Diffusion runs on consumer GPUs"],
      "hypernyms": ["diffusion_model.ai.01"],
      "hyponyms": [],
      "aliases": ["sd"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "peft.ai.01",
      "word": "peft",
      "pos": "n",
      "definition": "Parameter-Efficient Fine-Tuning, techniques that fine-tune only a small subset of model parameters",
      "examples": ["PEFT methods reduce fine-tuning costs", "LoRA is a popular PEFT technique"],
      "hypernyms": ["fine_tuning.ai.01"],
      "hyponyms": ["lora.ai.01", "prefix_tuning.ai.01"],
      "aliases": ["parameter_efficient_fine_tuning"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "constitutional_ai.ai.01",
      "word": "constitutional_ai",
      "pos": "n",
      "definition": "an approach to AI alignment where models critique and revise their own outputs based on a set of principles",
      "examples": ["Claude is trained using Constitutional AI", "Constitutional AI reduces the need for human feedback"],
      "hypernyms": ["alignment_technique.ai.01"],
      "hyponyms": [],
      "aliases": ["cai"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "benchmark.ai.01",
      "word": "benchmark",
      "pos": "n",
      "definition": "a standardized test or dataset used to evaluate and compare AI model performance",
      "examples": ["MMLU is a popular LLM benchmark", "Run benchmarks to compare model capabilities"],
      "hypernyms": ["evaluation.ai.01"],
      "hyponyms": ["mmlu.ai.01", "hellaswag.ai.01"],
      "aliases": ["ai_benchmark"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "semantic_search.ai.01",
      "word": "semantic_search",
      "pos": "n",
      "definition": "search that uses embeddings to find results based on meaning rather than exact keyword matches",
      "examples": ["Semantic search finds relevant documents even without exact terms", "Use embeddings for semantic search"],
      "hypernyms": ["search_technique.ai.01"],
      "hyponyms": [],
      "aliases": ["vector_search"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "cosine_similarity.ai.01",
      "word": "cosine_similarity",
      "pos": "n",
      "definition": "a metric measuring the cosine of the angle between two vectors, commonly used to compare embeddings",
      "examples": ["Use cosine similarity to find similar documents", "Cosine similarity ranges from -1 to 1"],
      "hypernyms": ["similarity_metric.ai.01"],
      "hyponyms": [],
      "aliases": [],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "huggingface.ai.01",
      "word": "huggingface",
      "pos": "n",
      "definition": "a platform and company providing tools, models, and datasets for machine learning, known for the Transformers library",
      "examples": ["Download models from Hugging Face Hub", "Use the Hugging Face Transformers library"],
      "hypernyms": ["ml_platform.ai.01"],
      "hyponyms": [],
      "aliases": ["hf", "hugging_face"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "langchain.ai.01",
      "word": "langchain",
      "pos": "n",
      "definition": "a framework for developing applications powered by language models, providing tools for chains, agents, and retrieval",
      "examples": ["Build RAG applications with LangChain", "LangChain simplifies LLM application development"],
      "hypernyms": ["framework.ai.01"],
      "hyponyms": [],
      "aliases": [],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "llamaindex.ai.01",
      "word": "llamaindex",
      "pos": "n",
      "definition": "a data framework for building LLM applications, specializing in data ingestion, indexing, and retrieval",
      "examples": ["Use LlamaIndex for document Q&A", "LlamaIndex provides various index structures"],
      "hypernyms": ["framework.ai.01"],
      "hyponyms": [],
      "aliases": ["llama_index"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "vllm.ai.01",
      "word": "vllm",
      "pos": "n",
      "definition": "a high-throughput LLM serving library using PagedAttention for efficient memory management",
      "examples": ["Deploy models with vLLM for high throughput", "vLLM supports continuous batching"],
      "hypernyms": ["inference_engine.ai.01"],
      "hyponyms": [],
      "aliases": [],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "ollama.ai.01",
      "word": "ollama",
      "pos": "n",
      "definition": "a tool for running large language models locally with a simple command-line interface",
      "examples": ["Run Llama locally with Ollama", "Ollama makes local LLM deployment easy"],
      "hypernyms": ["inference_tool.ai.01"],
      "hyponyms": [],
      "aliases": [],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "groq.ai.01",
      "word": "groq",
      "pos": "n",
      "definition": "an AI inference company known for extremely fast LLM inference using custom LPU hardware",
      "examples": ["Groq provides the fastest LLM inference", "Use Groq API for low-latency responses"],
      "hypernyms": ["inference_provider.ai.01"],
      "hyponyms": [],
      "aliases": [],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "mcp.ai.01",
      "word": "mcp",
      "pos": "n",
      "definition": "Model Context Protocol, a standard protocol for connecting AI models to external data sources and tools",
      "examples": ["Use MCP to connect Claude to your data", "MCP servers expose capabilities to AI models"],
      "hypernyms": ["protocol.ai.01"],
      "hyponyms": [],
      "aliases": ["model_context_protocol"],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    },
    {
      "synset_id": "agentic.ai.01",
      "word": "agentic",
      "pos": "a",
      "definition": "relating to AI systems that can take autonomous actions and make decisions to achieve goals",
      "examples": ["Build agentic workflows with tool use", "Agentic AI can complete multi-step tasks"],
      "hypernyms": [],
      "hyponyms": [],
      "aliases": [],
      "domain": "AI_ML",
      "source": "bootstrap",
      "confidence": 1.0
    }
  ]
}
